package ClassificationModule

import org.apache.spark.{SparkConf, SparkContext}

import scala.io.Source

object Test2 {
  def main(args: Array[String]): Unit = {
//    val conf = new SparkConf()
//      .setAppName("kafkaTest")
//    val sc = new SparkContext(conf)
//
//    val filePaths = Array("hdfs://spark1:9000/Hamlet.txt")
//    val filePathsRDD = sc.parallelize(filePaths)
//    val fileWordCountRDD = filePathsRDD.map(f => {
//      val source = Source.fromFile(f)
//      val lines = source.getLines()
//      lines.length
//    })
//    fileWordCountRDD.foreach(println(_))
  }

//  val source = Source.fromFile("hdfs://spark1:9000/Hamlet.txt")
//  val lines = source.getLines()
  println("hello world")
}
